cerebras:
    save_iter_state_path: /path/to/save/dir
train_input:
    # Tokens: 119931863040
    # Params: 6583754752
    # FLOPs/seq: 95083236884480.0
    data_processor: "GptHDF5MapDataProcessor"
    use_worker_cache: False
    repeat: True
    shuffle: False
    shuffle_seed: 1
#   batch_size: 1584 # set it same as the phase1 and phase2 batch size
    batch_size: 2112 # 2112 global = (66 micro)*(16-box)*(2 grad accum steps)
    # micro_batch_size: 88
    vocab_size: 32032
    num_workers: 1
    prefetch_factor: 10
    persistent_workers: True
    mixture:
    - data_dir: "/path/to/stage3_fim_0.3/train_shuffled_correct_ratio/css"
      weight: 0.08792775542527535
    - data_dir: "/path/to/stage3_fim_0.3/train_shuffled_correct_ratio/javascript"
      weight: 0.18370762129027085
    - data_dir: "/path/to/stage3_fim_0.3/train_shuffled_correct_ratio/html"
      weight: 0.18536747298179254
    - data_dir: "/path/to/stage3_fim_0.3/train_shuffled_correct_ratio/python"
      weight: 0.34270089587947816
    - data_dir: "/path/to/SlimPajama/ArXiv_train_packed"
      weight: 0.016663255966286664
      data_subset: 0.0-0.1
    - data_dir: "/path/to/SlimPajama/Book_train_packed"
      weight: 0.00831444671835677
      data_subset: 0.0-0.1
    - data_dir: "/path/to/SlimPajama/C4_train_packed"
      weight: 0.01685693658811707
      data_subset: 0.0-0.1
    - data_dir: "/path/to/SlimPajama/CommonCrawl_train_packed"
      weight: 0.058282893778895735
      data_subset: 0.0-0.1
    - data_dir: "/path/to/SlimPajama/StackExchange_train_packed"
      weight: 0.008379821974060706
      data_subset: 0.0-0.1
    - data_dir: "/path/to/SlimPajama/Wikipedia_train_packed"
      weight: 0.05835852419497722
      data_subset: 0.0-0.1
    - data_dir: "/path/to/StarCoder_fim_train_shuffled/"
      weight: 0.0334403752024888
      data_subset: 0.0-0.1
eval_input:
    data_processor: "GptHDF5MapDataProcessor"
    data_dir:
      - "/path/to/stage3_fim_0.3/valid_correct_ratio/css" # 4450 samples
      - "/path/to/stage3_fim_0.3/valid_correct_ratio/javascript" # 10435 samples
      - "/path/to/stage3_fim_0.3/valid_correct_ratio/html" # 11906 samples
      - "/path/to/stage3_fim_0.3/valid_correct_ratio/python" # 21320 samples
      - "/path/to/slimpj_arxiv_val_packed" # 12239 samples
      - "/path/to/slimpj_book_val_packed" # 12285 samples
      - "/path/to/slimpj_c4_val_packed" # 76178 samples
      - "/path/to/slimpj_commoncrawl_val_packed" # 152448 samples
      - "/path/to/slimpj_stackexchange_val_packed" # 9061 samples
      - "/path/to/slimpj_wikipedia_val_packed" # 9711 samples
      - "/path/to/StarCoder_fim_val/" # 300000 samples
    use_worker_cache: False
    vocab_size: 32032
    batch_size: 32
    repeat: False
    shuffle: False
    num_workers: 1
model:
    hidden_size: 4096
    use_position_embedding: True
    position_embedding_type: "rotary"
    share_embedding_weights: True
    max_position_embeddings: 2048
    vocab_size: 32032
    num_hidden_layers: 32
    dropout_rate: 0.0
    layer_norm_epsilon: 1.0e-05
    num_heads: 32
    attention_type: "scaled_dot_product"
    attention_dropout_rate: 0.0
    use_projection_bias_in_attention: True
    use_ffn_bias_in_attention: True
    filter_size: 10922
    nonlinearity: "swiglu"
    use_ffn_bias: True
    embedding_initializer:
        mean: 0.0
        name: "truncated_normal"
        std: 0.073
        a: -0.146
        b: 0.146
    initializer:
        mean: 0.0
        name: "truncated_normal"
        std: 0.01825
        a: -0.0365
        b: 0.0365
    output_layer_initializer:
        mean: 0.0
        name: "truncated_normal"
        std: 0.00228125
        a: -0.0045625
        b: 0.0045625
    use_bias_in_output: False
    weight_initialization_seed: 1
    mixed_precision: True
    boundary_casting: False
    use_bfloat16: True
    attention_kernel: "optimized_beta"
    output_logits_scale: 0.13875
    scale_qk_dot_by_d: True
    embeddings_scale: 14.6
    # Loss normalization: batch_size for loss_scaling and 1/msl for loss_weight
    loss_scaling: "batch_size"
    loss_weight: 0.00048828125 # 1/2048.0
    rotary_dim: 32
    scale_glu_initialization: True
optimizer:
    optimizer_type: "AdamW"
    beta1: 0.9
    beta2: 0.95
    eps: 1.0e-09
    max_gradient_norm: 1.0
    learning_rate:
    - scheduler: "Linear"
      initial_learning_rate: 0.0
      end_learning_rate: 0.002
      steps: 276 # 1% tokens warmup
    - scheduler: "Linear"
      initial_learning_rate: 0.002
      end_learning_rate: 0.0002
      decay_steps: 27452 # 27590 - 138
    weight_decay_rate: 0.1
    log_summaries: True
    correct_bias: True
    adjust_learning_rate:
        decoder_kernel: 0.0625
runconfig:
    max_steps: 27728
    eval_steps: 19375
    enable_distributed: False
    checkpoint_steps: 1000
    log_steps: 1
    save_initial_checkpoint: False
    use_appliance_data: True
    seed: 1
    precision_opt_level: -1
    use_cs_grad_accum: True
    is_pretrained_checkpoint: True
    mgmt_namespace: rel-191-g42
    wrk_memory_gi: 100
